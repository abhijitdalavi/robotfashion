# DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations

[paper can be found here](./pdf/deepfashion.pdf)

## Motivation

3 problems with clothes recognition algorithms:
1. large variations in style, texture and cutting
2. frequency deformation and occlusion
3. variation between scenarios (selfies vs online shopping photos)

Solutions:
1. annotating with semantic attributes (color, category, texture)
2. annotating with clothing location (masks of clothes)
3. cross-domain image correspondences

Previous datasets annotated with different information of the 3 solutions above.
This work creates a unified dataset with all of the above information/solutions.

A new deep learning structure, FashionNet, is proposed as state-of-the-art for
these benchmarks.

The contributions of this work are:
1. building DeepFashion dataset
2. presenting FashionNet
3. define benchmarks and evaluation protocols

## Methodology

### Dataset

* 800k images
* each image is labeled with 50 categories, 1000 attributes (with groups texture, fabric, shape, part, style) and  4~8 clothing landmarks (bounding boxes of important locations in the clothing).
* 300k pairs of images which provide cross-pose/cross-domain information (for example: online-webshop image and user selfie of same clothing item)

Images where taken from 2 online clothing webshops and from Google Images. Duplicates were taken out by fc7-responses of AlexNet and human annotators removed unusable images.

Category and attribute lists where obtained by traversing several online retailers and storing names of items (such as "animal print dress"). Nouns define categories and adjectives attributes. 50 unique nouns were found, and the 1000 most frequent adjectives were selected.

Categories were annotated by humans and each item has only 1 category.

Attributes were assigned automatically by using meta-data of image.

Land marks were annotated manually. Each landmark also has a label whether it's occluded or not.

Pairwise images are generated by how the images were collected. Image pairs with a
noisy image were removed.

### Benchmarks

This dataset allows for benchmarks:
1. clothing category and attribute prediction
  * category prediction uses top-k classification accuracy
  * attribute prediction uses top-k recall rate
2. in-shop clothes retrieval
  * decide whether two images the same clothing item
  * only includes "nice" in-shop images
  * metric: top-k retrieval accuracy (retrieval = exact item in top-k results)
3. cross-domain clothes retrieval
  * same as 2, but match consumer picture to shopping picture

### FashionNet

Details of FashionNet are not currently relevant.

## Solution

Experimental results of FashionNet are not currently relevant.
